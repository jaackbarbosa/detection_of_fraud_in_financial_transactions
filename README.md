# ğŸ§  DetecÃ§Ã£o de Fraudes em TransaÃ§Ãµes Financeiras com Machine Learning

---
## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto tem como objetivo desenvolver um modelo de **machine learning supervisionado** capaz de **identificar transaÃ§Ãµes potencialmente fraudulentas em cartÃµes de crÃ©dito**, utilizando um conjunto de dados reais anonimizados.  

A detecÃ§Ã£o de fraudes Ã© um dos desafios mais relevantes no setor financeiro, exigindo soluÃ§Ãµes que conciliem **precisÃ£o, velocidade e interpretabilidade** para minimizar perdas e proteger clientes.

---
## âš–ï¸ Desbalanceamento

Um dos principais desafios deste projeto Ã© o **forte desbalanceamento entre as classes**, algo comum em problemas reais de detecÃ§Ã£o de fraudes.  
O conjunto de dados contÃ©m **284.807 transaÃ§Ãµes**, sendo apenas **492 fraudulentas (0,17%)** e **284.315 legÃ­timas (99,83%)**.  

Esse cenÃ¡rio torna o problema especialmente difÃ­cil, pois um modelo que previsse â€œnÃ£o fraudeâ€ para todos os casos ainda teria **acurÃ¡cia de 99,8%**, mas **nÃ£o teria utilidade prÃ¡tica**.  
O modelo **XGBoost** foi configurado com um **ajuste ponderado entre as classes (`scale_pos_weight`)**, o que permitiu uma aprendizagem mais equilibrada e maior sensibilidade Ã  classe minoritÃ¡ria.

![distribuiÃ§Ã£o_das_classes_de_transaÃ§Ãµes.png](./relatorios/imagens/distribuicao_das_classes_de_transacoes.png)

---
## ğŸ§© Principais resultados
O estudo foi dividido em trÃªs partes principais, cada uma com seu prÃ³prio caderno na pasta `notebooks`:

1. **AnÃ¡lise exploratÃ³ria e prÃ©-processamento nos dados:** identificaÃ§Ã£o de padrÃµes entre transaÃ§Ãµes legÃ­timas e fraudulentas, padronizaÃ§Ã£o e normalizaÃ§Ã£o dos atributos, tratamento de outliers e variÃ¡veis desbalanceadas. Para verificar quais variÃ¡veis realmente apresentavam relaÃ§Ã£o significativa com a variÃ¡vel alvo, foi aplicado o teste nÃ£o paramÃ©trico U de Mannâ€“Whitney, ideal para distribuiÃ§Ãµes assimÃ©tricas e sem pressuposto de normalidade. [Caderno 1](notebooks/01-jb_eda.ipynb)

2. **ComparaÃ§Ã£o de modelos e seleÃ§Ã£o final:** foram avaliados modelos lineares, baseados em Ã¡rvore e KNN. O XGBoost apresentou o melhor equilÃ­brio entre *recall*, *precision* e *AUPRC*, sendo escolhido como modelo final.  
   - O **XGBClassifier** permite o ajuste de pesos entre classes, dispensando reamostragem manual.
   - Sua estrutura baseada em *gradient boosting* com regularizaÃ§Ã£o L1/L2 o torna ideal para grandes volumes de dados e alta assimetria entre classes. [Caderno 2](notebooks/02-jb_modelos.ipynb).
</br></br>
3. **Modelagem com subamostragem:** foi testado o uso do **XGBoost com subamostragem (undersampling)** para o equilibrio de classes antes do treinamento. No entanto, observou-se uma **queda no desempenho geral do modelo**, com **aumento significativo de falsos positivos** e menor capacidade de generalizaÃ§Ã£o. Por esse motivo, o mÃ©todo **nÃ£o foi adotado na versÃ£o final** do projeto. [Caderno 3](notebooks/03-jb_modelos_rus.ipynb).

O desempenho do modelo final foi avaliado usando a Ãrea Sob a Curva de PrecisÃ£o-Recall (AUPRC), que Ã© o equilÃ­brio entre PrecisÃ£o e Recall. Abaixo, uma comparaÃ§Ã£o das mÃ©tricas do modelo:

![comparar_metricas_modelos.png](relatorios/imagens/comparar_metricas_modelos.png)

---
## ğŸ“Š ConclusÃ£o

O **XGBoost ajustado com ponderaÃ§Ã£o de classes** se mostrou a melhor soluÃ§Ã£o para o problema de detecÃ§Ã£o de fraudes, apresentando **Ã³timo equilÃ­brio entre precisÃ£o e recall** mesmo diante de um forte desbalanceamento.  

O **processo de ajuste de hiperparÃ¢metros (GridSearchCV)** utilizou como mÃ©trica de refit a **Ã¡rea sob a curva de PrecisÃ£o-Recall (AUPRC)** â€” uma escolha apropriada para cenÃ¡rios de detecÃ§Ã£o de fraudes, pois enfatiza o desempenho em relaÃ§Ã£o Ã  classe minoritÃ¡ria e penaliza falsos positivos de forma mais realista.

O modelo **XGBClassifier** identificou corretamente **100% das 492 fraudes**, alÃ©m de errar apenas **3 transaÃ§Ãµes** dentre as **256.088** classificadas como legÃ­timas, representando uma proporÃ§Ã£o extremamente pequena de **0,000012% de identificaÃ§Ãµes incorretas**.

A matriz de confusÃ£o abaixo ilustra o desempenho final do modelo:

![matriz_confusao.png](relatorios/imagens/matriz_confusao.png)
> Legenda:  
>- **True label:** Classe real da transaÃ§Ã£o  
>- **Predicted label:** Classe prevista pelo modelo

Em sÃ­ntese, o projeto evidencia a importÃ¢ncia de modelos robustos e interpretÃ¡veis para a detecÃ§Ã£o de fraudes financeiras, mostrando como a ciÃªncia de dados pode apoiar decisÃµes automatizadas e preventivas em contextos crÃ­ticos de negÃ³cios.

---
## ğŸ’¼ PossÃ­veis AplicaÃ§Ãµes PrÃ¡ticas
A soluÃ§Ã£o proposta pode ser aplicada em diferentes contextos:

- ğŸ¦ **InstituiÃ§Ãµes financeiras** â€” monitoramento em tempo real de transaÃ§Ãµes para bloqueio automÃ¡tico de fraudes.  
- ğŸ’³ **Empresas de cartÃ£o de crÃ©dito e fintechs** â€” apoio Ã  equipe antifraude na priorizaÃ§Ã£o de alertas e investigaÃ§Ã£o de transaÃ§Ãµes suspeitas.  
- ğŸ›’ **E-commerces e plataformas digitais** â€” reduÃ§Ã£o de *chargebacks*, fraudes em pagamentos e contas falsas.  
- ğŸ” **Auditorias e compliance** â€” identificaÃ§Ã£o de padrÃµes anÃ´malos em grandes volumes de dados financeiros.  
- ğŸ§¾ **Seguradoras e corretoras** â€” detecÃ§Ã£o de sinistros irregulares e comportamentos suspeitos em pedidos de indenizaÃ§Ã£o.  
- ğŸ’¹ **Corretoras de investimentos e bolsas** â€” monitoramento de operaÃ§Ãµes suspeitas e prevenÃ§Ã£o de lavagem de dinheiro (*AML*).  
- ğŸ§  **Centros de anÃ¡lise de risco** â€” integraÃ§Ã£o de modelos preditivos em pipelines de *credit scoring* e concessÃ£o de crÃ©dito.  
- ğŸ¢ **Empresas de consultoria e BPO financeiro** â€” desenvolvimento de soluÃ§Ãµes automatizadas de auditoria e controle interno.  
- ğŸ§® **Departamentos de contabilidade e tesouraria corporativa** â€” verificaÃ§Ã£o automÃ¡tica de inconsistÃªncias em movimentaÃ§Ãµes e reconciliaÃ§Ãµes bancÃ¡rias.  
 

AlÃ©m do ganho operacional, o projeto demonstra **como a ciÃªncia de dados pode gerar valor direto ao negÃ³cio**, diminuindo perdas financeiras e melhorando a experiÃªncia do cliente.

---
## ğŸ“‚ Estrutura do Projeto

```
â”œâ”€â”€ dados/                  <- Conjunto de dados (.parquet, .zip)
â”œâ”€â”€ modelos/                <- Modelos treinados e serializados
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01-jb_eda.ipynb     <- AnÃ¡lise exploratÃ³ria dos dados
â”‚   â”œâ”€â”€ 02-jb_modelos.ipynb <- Modelos iniciais e mÃ©tricas
â”‚   â”œâ”€â”€ 03-jb_modelos_rus.ipynb <- Modelos com subamostragem
â”‚   â””â”€â”€ src/                <- CÃ³digo-fonte modularizado
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ graficos.py
â”‚       â”œâ”€â”€ models.py
â”‚       â””â”€â”€ models_rus.py
â”œâ”€â”€ referencias/            <- DicionÃ¡rio de dados e documentaÃ§Ã£o
â”œâ”€â”€ relatorios/             <- Imagens e relatÃ³rios gerados
â”œâ”€â”€ identificacao_fraudes.yml <- Requisitos de ambiente Conda
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---
## ğŸ§° Tecnologias Utilizadas
```
- Python 3.12.5
- pathlib
- Pandas, NumPy, Matplotlib, Seaborn
- Scikit-learn
- Scipy
- LightGBM
- XGBoost
- Imbalanced-learn
- Jupyter Notebook
- Conda / Anaconda
```

Todas as bibliotecas estÃ£o listadas no arquivo `identificacao_fraudes.yml`.

---
## âš™ï¸ ConfiguraÃ§Ã£o do Ambiente

1. FaÃ§a o clone do repositÃ³rio:
    ```bash
    git clone git@github.com:jaackbarbosa/detection_of_fraud_in_financial_transactions.git
    ```

2. Crie um ambiente virtual e exporte as dependÃªncias:
    ```bash
    conda env export > identificacao_fraudes.yml
    ```
---
## ğŸ“œ LicenÃ§a

Este projeto estÃ¡ licenciado sob os termos da [MIT License](LICENSE). </br>
Esta licenÃ§a Ã© permissiva e permite que outros usem, modifiquem e distribuam seu cÃ³digo, desde que a licenÃ§a original e os avisos de copyright sejam incluÃ­dos.

---
## ğŸ‘¤ Autor

**Desenvolvido por:** Jackson da Silva Barbosa  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/jaacksilva/)  
ğŸ’» [GitHub](https://github.com/jaackbarbosa)  

ğŸ“ Projeto voltado a aplicaÃ§Ãµes reais em CiÃªncia de Dados e DetecÃ§Ã£o de Fraudes Financeiras.